{
  "nbformat_minor": 0, 
  "nbformat": 4, 
  "cells": [
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "%matplotlib inline"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "\n# Generate Images\n\n\nThis ipython notebook demonstrates how to generate an image dataset with rich\nground truth from a virtual environment.\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "import time; print(time.strftime(\"The last update of this file: %Y-%m-%d %H:%M:%S\", time.gmtime()))"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Load some python libraries\nThe dependencies for this tutorials are\nPIL, Numpy, Matplotlib\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "from __future__ import division, absolute_import, print_function\nimport os, sys, time, re, json\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimread = plt.imread\ndef imread8(im_file):\n    ''' Read image as a 8-bit numpy array '''\n    im = np.asarray(Image.open(im_file))\n    return im\n\ndef read_png(res):\n    import StringIO, PIL.Image\n    img = PIL.Image.open(StringIO.StringIO(res))\n    return np.asarray(img)\n\ndef read_npy(res):\n    import StringIO\n    return np.load(StringIO.StringIO(res))"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Connect to the game\n===================\nLoad unrealcv python client, do :code:`pip install unrealcv` first.\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "from unrealcv import client\nclient.connect()\nif not client.isconnected():\n    print('UnrealCV server is not running. Run the game downloaded from http://unrealcv.github.io first.')\n    sys.exit(-1)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Make sure the connection works well\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "res = client.request('vget /unrealcv/status')\n# The image resolution and port is configured in the config file.\nprint(res)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Load a camera trajectory\n========================\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "traj_file = './camera_traj.json' # Relative to this python script\nimport json; camera_trajectory = json.load(open(traj_file))\n# We will show how to record a camera trajectory in another tutorial"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Render an image\n===============\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "idx = 1\nloc, rot = camera_trajectory[idx]\n# Set position of the first camera\nclient.request('vset /camera/0/location {x} {y} {z}'.format(**loc))\nclient.request('vset /camera/0/rotation {pitch} {yaw} {roll}'.format(**rot))\n\n# Get image\nres = client.request('vget /camera/0/lit lit.png')\nprint('The image is saved to %s' % res)\n\n# It is also possible to get the png directly without saving to a file\nres = client.request('vget /camera/0/lit png')\nim = read_png(res)\nprint(im.shape)\n\n# Visualize the image we just captured\nplt.imshow(im)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Ground truth generation\n=======================\nGenerate ground truth from this virtual scene\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "res = client.request('vget /camera/0/object_mask png')\nobject_mask = read_png(res)\nres = client.request('vget /camera/0/normal png')\nnormal = read_png(res)\n\n# Visualize the captured ground truth\nplt.imshow(object_mask)\nplt.figure()\nplt.imshow(normal)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Depth is retrieved as a numpy array\nFor UnrealCV < v0.3.8, the depth is saved as an exr file, but this has two issues. 1. Exr is not well supported in Linux 2. It depends on OpenCV to read exr file, which is hard to install\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "res = client.request('vget /camera/0/depth npy')\ndepth = read_npy(res)\nplt.imshow(depth)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Get object information\n======================\nList all the objects of this virtual scene\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "scene_objects = client.request('vget /objects').split(' ')\nprint('Number of objects in this scene:', len(scene_objects))\n\n# TODO: replace this with a better implementation\nclass Color(object):\n    ''' A utility class to parse color value '''\n    regexp = re.compile('\\(R=(.*),G=(.*),B=(.*),A=(.*)\\)')\n    def __init__(self, color_str):\n        self.color_str = color_str\n        match = self.regexp.match(color_str)\n        (self.R, self.G, self.B, self.A) = [int(match.group(i)) for i in range(1,5)]\n\n    def __repr__(self):\n        return self.color_str\n\nid2color = {} # Map from object id to the labeling color\nfor obj_id in scene_objects:\n    color = Color(client.request('vget /object/%s/color' % obj_id))\n    id2color[obj_id] = color\n    # print('%s : %s' % (obj_id, str(color)))"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Parse the segmentation mask\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "def match_color(object_mask, target_color, tolerance=3):\n    match_region = np.ones(object_mask.shape[0:2], dtype=bool)\n    for c in range(3): # r,g,b\n        min_val = target_color[c] - tolerance\n        max_val = target_color[c] + tolerance\n        channel_region = (object_mask[:,:,c] >= min_val) & (object_mask[:,:,c] <= max_val)\n        match_region &= channel_region\n\n    if match_region.sum() != 0:\n        return match_region\n    else:\n        return None\n\nid2mask = {}\nfor obj_id in scene_objects:\n    color = id2color[obj_id]\n    mask = match_color(object_mask, [color.R, color.G, color.B], tolerance = 3)\n    if mask is not None:\n        id2mask[obj_id] = mask\n# This may take a while\n# TODO: Need to find a faster implementation for this"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Print statistics of this virtual scene and this image\n=====================================================\nLoad information of this scene\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "with open('object_category.json') as f:\n    id2category = json.load(f)\ncategories = set(id2category.values())\n# Show statistics of this frame\nimage_objects = id2mask.keys()\nprint('Number of objects in this image:', len(image_objects))\nprint('%20s : %s' % ('Category name', 'Object name'))\nfor category in categories:\n    objects = [v for v in image_objects if id2category.get(v) == category]\n    if len(objects) > 6: # Trim the list if too long\n        objects[6:] = ['...']\n    if len(objects) != 0:\n        print('%20s : %s' % (category, objects))"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Show the annotation color of some objects\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "ids = ['SM_Couch_1seat_5', 'SM_Vase_17', 'SM_Shelving_6', 'SM_Plant_8']\n# for obj_id in ids:\nobj_id = ids[0]\ncolor = id2color[obj_id]\nprint('%s : %s' % (obj_id, str(color)))\n# color_block = np.zeros((100,100, 3)) + np.array([color.R, color.G, color.B]) / 255.0\n# plt.figure(); plt.imshow(color_block); plt.title(obj_id)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Plot only one object\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "mask = id2mask['SM_Plant_8']\nplt.figure(); plt.imshow(mask)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Show all sofas in this image\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "couch_instance = [v for v in image_objects if id2category.get(v) == 'Couch']\nmask = sum(id2mask[v] for v in couch_instance)\nplt.figure(); plt.imshow(mask)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Change the annotation color, fixed in v0.3.9\nYou can use this to make objects you don't care the same color\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "client.request('vset /object/SM_Couch_1seat_5/color 255 0 0') # Change to pure red\nclient.request('vget /object/SM_Couch_1seat_5/color')\nres = client.request('vget /camera/0/object_mask png')\nobject_mask = read_png(res)\nplt.imshow(object_mask)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Clean up resources\n==================\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "client.disconnect()"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2", 
      "name": "python2", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "2.7.6", 
      "pygments_lexer": "ipython2", 
      "codemirror_mode": {
        "version": 2, 
        "name": "ipython"
      }
    }
  }
}